{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0c76933cfbe346ee382be0aefab6c87c10035cb793a59c5b7fb7184d7b059d578",
   "display_name": "Python 3.8.5 64-bit ('tf23': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# DICOManager Tutorial\n",
    "\n",
    "## Overview\n",
    "\n",
    "DICOManager is designed to sort, reconstruct, process and convert DICOM files to numpy arrays for use in Machine Learning and Deep Learning.\n",
    "\n",
    "## Sorting\n",
    "\n",
    "DICOManager begins with sorting DICOMs into a file tree with the following heirarchy:\n",
    "\n",
    "1. Cohort\n",
    "2. Patient\n",
    "3. Study\n",
    "4. Frame Of Reference\n",
    "5. Series \n",
    "6. Modality\n",
    "7. DICOM file\n",
    "\n",
    "File tree construction is automatic and can be called at any level using `groupings.<type>(files=<list_of_files>)`\n",
    "\n",
    "For example:\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cohort: MyCohort\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import groupings\n",
    "\n",
    "files = glob('/list/to/dicoms/*.dcm')\n",
    "cohort = groupings.Cohort(name='MyCohort', files=files)\n",
    "print(cohort)"
   ]
  },
  {
   "source": [
    "Upon each grouping level, the following basic functions can be used to alter the organization of the file tree, with `tree` refering to the current tree, `->` refering to the returned object:\n",
    "- `tree.merge(other) -> None`: Merge two trees \n",
    "- `tree.steal(other) -> None`: Moves a child of one tree to another tree\n",
    "- `tree.append(other) -> None`: Appends a node to another tree \n",
    "- `tree.prune(childname) -> None`: Removes a child from the tree \n",
    "- `tree.adopt(child) -> None`: Adopts a child to the current tree\n",
    "- `tree.flatten() -> None`: Restricts each parent to having one child within the tree \n",
    "- `tree.pop() -> <child type>`: Removes the first child from the tree and returns it \n",
    "- `save_dicoms(filepath) -> None`: Saves only the dicoms from the tree \n",
    "- `save_volumes(filepath) -> None`: Saves only the reconstructed volumes from the tree \n",
    "- `only_dicoms() -> bool`: Returns true if tree only contains dicoms\n",
    "- `has_dicoms() -> bool`: Returns true if tree contains dicoms\n",
    "- `has_volumes() -> bool`: Returns true if tree contains volumes\n",
    "- `iter_modalities() -> iterator`: Returns iterator of modalities within the tree\n",
    "- `iter_frames() -> iterator`: Returns iterator of frames of reference within the tree\n",
    "- `iter_dicoms() -> iterator`: Returns iterator of lists of dicoms for each series\n",
    "- `iter_volumes() -> iterator`: Returns iterator of each volume within the tree\n",
    "- `iter_volumes_frames() -> iteratorr`: Returns an iterator of all volumes within each frame of references\n",
    "- `clear_dicoms() -> None`: Removes all dicoms from a tree\n",
    "- `clear_volumes() -> None`: Removes all volumes from a tree\n",
    "- `split_tree() -> tuple`: Splits the tree into a dicom only and volume only tree\n",
    "- `split_dicoms() -> tree`: Returns only a tree of dicoms, removes dicoms from source tree\n",
    "- `split_volumes() -> tree`: Returns only a tree of volumes, removes volumes from source tree\n",
    "- `volumes_to_pointers() -> None`: Converts all volumes to pointers, writing the arrays to disk\n",
    "- `pointers_to_volumes() -> None`: Converts all pointer to volumes, loading the arrays into memory \n",
    "- `recon(in_memory=False, parallelize=True) -> None`: Reconstructs all DICOMs within the tree, loading into memory or writing to disk at ~/.\n",
    "\n",
    "An example for a few is below:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if the cohort contains dicoms\n",
    "print(cohort.has_dicoms())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten all patients\n",
    "for patient in cohort:\n",
    "    patient.flatten()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adopting the first 3 patients into a new cohort\n",
    "new_cohort = groupings.Cohort(name='NewCohort', files=None)\n",
    "\n",
    "for _ in range(3):\n",
    "    patient = cohort.pop()\n",
    "    new_cohort.adopt(patient)\n",
    "\n",
    "print(cohort)\n",
    "print(new_cohort)"
   ]
  },
  {
   "source": [
    "## Reconstruction\n",
    "Reconstructing DICOMs into numpy arrays suitable for AI can be time consuming and tedious. DICOManager quickly converts DICOMs into volumes using parallelized processes. The simpliest way to reconstruct a patient or cohort is using the `.recon()` function. This function supports reconstruction of CT, MR, PET, NM, RTSTRUCT and RTDOSE files. Default behavior is to write the reconstructed volumes to disk and place a pointer within the tree indicating the volume location. If `.recon(in_memory=True)`, then the volume will be stored in the tree. This process is slower, does not allow for parallelization and can quickly consume an entire systems memory, but it is ideal for single patient inference or usage on systems where read-write access to disk is restricted. In some applications, parallelization across all CPU cores is not desired, in which case `.recon(parallelized=False)` can be used, at the expense of reconstruciton runtime. \n",
    "\n",
    "An example of reconstruction of our cohort is:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cohort.recon()\n",
    "print(new_cohort)\n",
    "\n",
    "new_cohort.pointers_to_volumes()\n",
    "print(new_cohort)"
   ]
  },
  {
   "source": [
    "## Image Manipulation\n",
    "Image manuplation of reconstructed volumes can be conducted on volumes which are stored within memory (for now). These image manuplations are then stored in the header fo the ReconstructedFile or ReconstructedVolume objects. The image manuplation functions, within `dicomanager.processing.tools` are:\n",
    "\n",
    "- `dose_max_points(dose_array, dose_coords)` -> np.ndarray: Returns the maximum point in index, or coordinates, of the dose array\n",
    "- `window_level(window, level)` -> ReconstructedVolume: Window and levels the reconstructed volume array\n",
    "- `normalize(img)` -> RecontructedVolume: Normalizes the reconstructedVolume\n",
    "- `standardize(img) -> ReconstructedVolume`: Standardizes the reconstructedVolume\n",
    "- `crop(img, centroid, crop_size) -> ReconstructedVolume`: Crops the ReconstructedVolume around the centroid to dimensions of crop_size. Will offset from centroid to maintain crop_size dimensions. Will add option for padding with zeros instead in a later revision of the function.\n",
    "- `resample(img, ratio) -> ReconstructedVolume`: Resamples the image by the ratio provided\n",
    "- `bias_field_correction(img) -> ReconstructedVolume`: Uses N4BiasFieldCorrection from SimpleITK\n",
    "\n",
    "Exmaple of cropping and window, leveling\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from processing import tools\n",
    "\n",
    "for vol in cohort.iter_volumes():\n",
    "    vol = tools.window_level(vol, window=400, level=800)\n",
    "    vol = tools.crop(vol, centroid=(100, 100, 50), crop_size=(250, 250, 50))"
   ]
  },
  {
   "source": [
    "## Deconstruction (Numpy to RTSTRUCT)\n",
    "In some instances, particularly inference, conversion from boolean numpy array to an RTSTRUCT is desired. For this to be possible, the associated image DICOM files must be contained within the tree. Deconstruction is only possible at the Frame Of Reference level, or lower, as the RTSTRUCT must contain the equivalent dimensions to a CT group. If a Frame of Reference contains more than one CT, deconstruction is not currently supported. \n",
    "\n",
    "Deconstruction can occur as:\n",
    "- `from_ct()`: Creates a new RTSTRUCT from a CT files based upon the CT header\n",
    "- `from_rt()`: Creates a new RTSTRUCT from an existin RTSTRUCT file\n",
    "- `to_rt()`: Appends a segmentation to an existing RTSTRUCT file\n",
    "\n",
    "An example of deconstruction is provided below:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = new_cohort.iter_frames()[0]  # One frame of reference from the cohort\n",
    "vol = frame.iter_volumes()[0]  # One volume from the frame of reference\n",
    "rtstruct = np.zeros((1, vol.shape))  # Create an example array for demonstration\n",
    "\n",
    "print(f'before: {frame}')\n",
    "frame.decon.from_ct(rtstruct)\n",
    "print(f'after: {frame}')"
   ]
  }
 ]
}